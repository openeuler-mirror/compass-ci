#!/usr/bin/env python3
# SPDX-License-Identifier: MulanPSL-2.0+
# Copyright (c) 2025 Huawei Technologies Co., Ltd. All rights reserved.
#   Input: manticore JSON
#
#   functions:
#
#       provide API/new-bisect-task
#           add to bisect_tasks
#       loop:
#           consumer:
#               one task from bisect_tasks
#               fork process, start bisect
#           producer:
#               scan job db
#               add failed task to bisect_tasks
#
import json
import re
import subprocess
import hashlib
from datetime import datetime
import yaml
import os
import sys
import shutil
import time
import traceback
import mysql.connector
import hashlib
import signal
import multiprocessing
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from random import randint
from flask import Flask, jsonify, request
from flask.views import MethodView
from httpx import RequestError
from functools import wraps


sys.path.append((os.environ['LKP_SRC']) + '/programs/bisect-py/')
from py_bisect import GitBisect
from log_config import logger
sys.path.append((os.environ['CCI_SRC']) + '/lib')
from bisect_database import BisectDB
from manticore_simple import ManticoreClient


app = Flask(__name__)


def generate_task_id(bad_job_id: str, error_id: str) -> int:
    """
    ç”Ÿæˆç¬¦åˆ Manticore è¦æ±‚çš„ 63 ä½æ­£æ•´æ•° ID
    ç®—æ³•ï¼šSHA256(ä¸šåŠ¡ID+æ—¶é—´æˆ³)[å‰16ä½] â†’ åå…­è¿›åˆ¶è½¬åè¿›åˆ¶ â†’ æ©ç ä¿ç•™63ä½
    
    Args:
        bad_job_id: æ•…éšœä»»åŠ¡ID
        error_id: é”™è¯¯æ ‡è¯†ç¬¦
        
    Returns:
        63ä½æ­£æ•´æ•° (JavaScript å®‰å…¨æ•´æ•°èŒƒå›´)
    """
    # 1. æ„é€ å”¯ä¸€å­—ç¬¦ä¸²
    timestamp = f"{time.time():.6f}"  # å¾®ç§’çº§æ—¶é—´æˆ³
    unique_str = f"{bad_job_id}|{error_id}|{timestamp}"
    
    # 2. è®¡ç®— SHA256 å“ˆå¸Œ
    hash_bytes = hashlib.sha256(unique_str.encode()).digest()
    
    # 3. å–å‰8å­—èŠ‚ï¼ˆ64ä½ï¼‰å¹¶è½¬æ¢ä¸ºæ•´æ•°
    hash_int = int.from_bytes(hash_bytes[:8], byteorder='big')
    
    # 4. ç¡®ä¿æœ€é«˜ä½ä¸º0ï¼Œå¾—åˆ°63ä½æ­£æ•´æ•°
    return hash_int & 0x7FFFFFFFFFFFFFFF

class BisectTask:
    @staticmethod
    def _init_process_resources(config):
        """å­è¿›ç¨‹èµ„æºåˆå§‹åŒ–"""
        global process_client
        process_client = ManticoreClient(
            host=config['manticore_host'],
            port=9308
        )

    @staticmethod
    def _generate_task_path(config: dict, task: dict) -> str:
        """è¿›ç¨‹å®‰å…¨çš„è·¯å¾„ç”Ÿæˆ""" 
        path = os.path.join(
            'bisect_results',
            re.sub(r'[^\w\-]', '_', task.get('suite', 'unknown_repo'))[:32],
            datetime.now().strftime("%Y-%m-%d"),
            str(task['bad_job_id']),
            hashlib.md5(task['error_id'].encode()).hexdigest()[:8],
            str(task['id'])
        )
        os.makedirs(path, exist_ok=True, mode=0o755)
        return os.path.abspath(path)

    def _register_signal_handlers(self):
        """æ³¨å†Œä¿¡å·å¤„ç†"""
        signal.signal(signal.SIGINT, self._handle_exit_signal)
        signal.signal(signal.SIGTERM, self._handle_exit_signal)
        logger.info("å·²æ³¨å†Œé€€å‡ºä¿¡å·å¤„ç†å™¨")

    def _handle_exit_signal(self, signum, frame):
        """ä¿¡å·å¤„ç†å›è°ƒ"""
        logger.warning(f"æ”¶åˆ°ç»ˆæ­¢ä¿¡å· {signum}ï¼Œå¼€å§‹æ¸…ç†...")
        self.running = False
        self._cleanup_interrupted_tasks()
        sys.exit(1)

    @staticmethod
    def _process_single_task(config: dict, task: dict):
        """é™æ€ä»»åŠ¡å¤„ç†æ–¹æ³•"""
        try:
            global process_bisect_db, process_client
            
            task_id = int(task['id'])
            task_result_root = BisectTask._generate_task_path(config, task)

            try:
                # ä½¿ç”¨ ManticoreClient çš„ search æ–¹æ³•æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                status_check = process_client.search(
                    table="bisect",
                    query={"match": {"id": task_id, "bisect_status": "wait"}},
                    limit=1
                )

                if not status_check:
                    logger.warning(f"è·³è¿‡æ— æ•ˆä»»åŠ¡ | ID: {task_id}")
                    return

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
                task["bisect_status"] = "processing"
                # Convert to Manticore SQL update

                if process_client.update("bisect", task_id, task):
                    logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ | ID: {task_id}")

                # å‡†å¤‡ä»»åŠ¡æ•°æ®
                task['bisect_result_root'] = task_result_root
                # æ‰§è¡Œ bisect
                logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ |  {task}")
                gb = GitBisect()
                result = gb.find_first_bad_commit(task)

                if result:
                    # æ„é€ å®Œæ•´ç»“æœæ–‡æ¡£
                    complete_doc = {
                        "bisect_status": "completed",
                        "project": result.get('repo', ''),
                        "git_url": result.get('git_url', ''),
                        "bad_commit": result.get('first_bad_commit', ''),
                        "first_bad_id": result.get('first_bad_id', ''),
                        "first_result_root": result.get('bad_result_root', ''),
                        "work_dir": result.get('work_dir', ''),
                        "start_time": result.get('start_time', 0),
                        "end_time": int(time.time()),
                        "updated_at": int(time.time())
                    }

                    # ä½¿ç”¨é‡è¯•æœºåˆ¶æ›´æ–°ç»“æœ
                    if not process_client.update("bisect", task_id, complete_doc):
                        logger.error(f"ç»“æœæ›´æ–°å¤±è´¥ | ID: {task_id}")
                    else:
                        # æ›´æ–°å›å½’æ•°æ®
                        BisectTask.update_regression(task, result)
                        logger.info(f"ä»»åŠ¡å®Œæˆ | ID: {task_id}")

                else:
                    # å¤„ç†å¤±è´¥æƒ…å†µ
                    fail_doc = {
                        "bisect_status": "failed",
                        "last_error": "Bisect execution failed",
                        "updated_at": int(time.time())
                    }
                    process_client.update("bisect", task_id, fail_doc)
                    logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥ | ID: {task_id}")

            except Exception as e:
                # å¼‚å¸¸å¤„ç†
                error_doc = {
                    "bisect_status": "failed",
                    "last_error": str(e)[:200],  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
                    "updated_at": int(time.time())
                }
                process_client.update("bisect", task_id, error_doc)
                logger.error(f"ä»»åŠ¡å¼‚å¸¸ | ID: {task_id} | é”™è¯¯: {str(e)}")
                logger.error(traceback.format_exc())
            
            return {'id': task_id, 'status': 'success'}
        except Exception as e:
            error_msg = f"Task {task_id} failed: {str(e)}"
            logger.error(error_msg)
            return {'id': task_id, 'status': 'failed', 'error': error_msg}

    def _cleanup_interrupted_tasks(self):
        """æ¸…ç†è¢«ä¸­æ–­çš„ä»»åŠ¡"""
        try:
            # 1. è·å–æ‰€æœ‰ processing çŠ¶æ€çš„ä»»åŠ¡
            tasks = self.bisect_db.execute_query(
                "SELECT id, work_dir as result_root FROM bisect "
                "WHERE bisect_status = 'processing'"
            )
            
            if tasks:
                logger.info(f"å‘ç° {len(tasks)} ä¸ªéœ€è¦æ¸…ç†çš„ä»»åŠ¡")

                # 2. æ›´æ–°çŠ¶æ€ä¸º wait
                update_sql = """
                    UPDATE bisect
                    SET bisect_status = 'wait'
                    WHERE bisect_status = 'processing'
                """
                self.bisect_db.execute_update(update_sql)
                logger.info(f"å·²é‡ç½® {len(tasks)} ä¸ªä»»åŠ¡çŠ¶æ€")

                # 3. åˆ é™¤æ•°æ®ç›®å½•
                for task in tasks:
                    result_root = task.get('result_root')
                    if result_root and os.path.exists(result_root):
                        try:
                            shutil.rmtree(result_root)
                            logger.info(f"æˆåŠŸåˆ é™¤æ•°æ®ç›®å½•: {result_root}")
                        except Exception as e:
                            logger.error(f"åˆ é™¤ç›®å½•å¤±è´¥ {result_root}: {str(e)}")

        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            logger.error(traceback.format_exc())
        finally:
            logger.info("èµ„æºæ¸…ç†å®Œæˆ")

    def __init__(self):
        self.bisect_task = None
        self.running = True  # è¿è¡ŒçŠ¶æ€æ ‡å¿—
        self.client = ManticoreClient(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=int(os.environ.get('MANTICORE_WRITE_PORT', '9308'))
        )
        self.jobs_db = BisectDB(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=os.environ.get('MANTICORE_PORT', '9306'),
            database="jobs",
            pool_size=2
        )
        logger.info(f"ä¸»è¿›ç¨‹ jobs DB è¿æ¥ ID: {id(self.jobs_db)}")

        self.bisect_db = BisectDB(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=os.environ.get('MANTICORE_PORT', '9306'),
            database="bisect",
            pool_size=2
        )
        logger.info(f"ä¸»è¿›ç¨‹ bisect DB è¿æ¥ ID: {id(self.bisect_db)}")

        # ä¸»è¿›ç¨‹æ•°æ®åº“è¿æ¥åˆå§‹åŒ–
        self.regression_db = BisectDB(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=os.environ.get('MANTICORE_PORT', '9306'),
            database="regression",
            pool_size=2
        )
        logger.info(f"ä¸»è¿›ç¨‹ RegressionDB è¿æ¥ ID: {id(self.regression_db)}")
        
        self._config = {
            "manticore_host": os.environ.get('MANTICORE_HOST', 'localhost'),
            "manticore_port": os.environ.get('MANTICORE_PORT', '9306'),
        }
        
        self.process_pool = ProcessPoolExecutor(
            max_workers=os.cpu_count(),
            initializer=self._init_process_resources,
            initargs=(self._config,)
        )
        self.task_futures = []
        
        self._register_signal_handlers()  # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        
        self._start_monitor()


    def add_bisect_task(self, task):
        """Add a new bisect task (atomic operation version)"""
        required_fields = ["bad_job_id", "error_id"]
        for field in required_fields:
            if field not in task:
                raise ValueError(f"Missing required field: {field}")

        try:
            # ç”ŸæˆåŸºäºä¸šåŠ¡æ•°æ®çš„å¼ºå”¯ä¸€ID
            task_fingerprint = generate_task_id(
                task["bad_job_id"], 
                task["error_id"]
            ) 
            # åŸå­æ’å…¥æ“ä½œ insert(self, index: str, id: int, document: dict) 
            if self.client.insert(index="bisect", id=task_fingerprint, document=task):
                return True
            else:
                return False
        except Exception as e:
            logger.error(f"Unknown error: {str(e)}")
            return False

    def set_priority_level(self, job_info: dict) -> int:
        """
        """
        WATCH_LISTS = {
            "suite": ["check_abi", "pkgbuild"],       # ç›‘æ§çš„æµ‹è¯•å¥—ä»¶
            "repo": ["linux"],                        # ç›‘æ§çš„ä»£ç ä»“åº“
            "error_id": ["stderr.eid../include/linux/thread_info.h:#:#:error:call_to'__bad_copy_from'declared_with_attribute_error:copy_source_size_is_too_small"]  # ç›‘æ§çš„é”™è¯¯ID
            }
              # ä¼˜å…ˆçº§æƒé‡é…ç½®
        PRIORITY_WEIGHTS = {
            "suite": 2,
            "repo": 1,
            "error_id": 3
        }

        priority = 0

        for field, weight in PRIORITY_WEIGHTS.items():
            # è·å–ä»»åŠ¡å­—æ®µå€¼ï¼ˆç¡®ä¿è¿”å›å­—ç¬¦ä¸²ï¼‰
            job_value = job_info.get(field, "")  # é»˜è®¤ç©ºå­—ç¬¦ä¸²

            # è·å–ç›‘æ§åˆ—è¡¨
            watch_list = WATCH_LISTS.get(field, [])

            # æ£€æŸ¥å€¼æ˜¯å¦åœ¨ç›‘æ§åˆ—è¡¨ä¸­
            if job_value in watch_list:
                priority += weight

        return priority

    def bisect_producer(self):
        """Producer function optimized for batch processing and rate limiting"""
        error_count = 0

        while self.running:
            if not self.running:
                logger.info("ç”Ÿäº§è€…çº¿ç¨‹æ”¶åˆ°åœæ­¢ä¿¡å·")
                break
            start_time = time.time()
            try:
                # Fetch new tasks with time filtering
                new_bisect_tasks = self.get_new_bisect_task_from_jobs()
                logger.info(f"Found {len(new_bisect_tasks)} candidate tasks")
                success_count = 0
                for task in new_bisect_tasks: 
                    if not self.bisect_db.execute_query(f"""SELECT id FROM bisect WHERE error_id='{task['error_id']}' AND bad_job_id='{task['bad_job_id']}'"""):
                        if self.add_bisect_task(task):
                            success_count += 1
                            logger.info(f"Add {task['error_id']} and {task['bad_job_id']} OK")
                
                error_count = max(0, error_count - 1)  # Reduce error count on success

            except Exception as e:
                # æ·»åŠ è¯¦ç»†é”™è¯¯æ—¥å¿—
                logger.error(f"Error in bisect_producer: {str(e)}")
                logger.error(f"Failed task data: {task if 'task' in locals() else 'No task data'}")
                logger.error(traceback.format_exc())  # æ‰“å°å®Œæ•´å †æ ˆè·Ÿè¸ª
                # æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
                sleep_time = min(300, 2 ** error_count)
                time.sleep(sleep_time)
                error_count += 1
            else:
                # æ­£å¸¸æ‰§è¡Œåé‡ç½®é”™è¯¯è®¡æ•°å™¨
                error_count = 0
                cycle_time = time.time() - start_time
                logger.info(f"Producer cycle completed.")
                # å›ºå®šé—´éš”ä¼‘çœ ï¼Œä¸¤ä¸ªå¾ªç¯ä¹‹é—´çš„é—´éš”æ°¸è¿œä¸º300ç§’ï¼Œæ— è®ºæ¯æ¬¡å¾ªç¯çš„æ‰§è¡Œæ—¶é—´ä¸ºå¤šå°‘
                sleep_time = 300 - cycle_time
                logger.info(f"Sleeping for {sleep_time:.2f} seconds until next cycle")
                time.sleep(sleep_time)

    def bisect_consumer(self):
        """
        Consumer function to fetch bisect tasks from Elasticsearch and process them.
        This function runs in an infinite loop, checking for tasks every 30 seconds.
        Tasks are either submitted to a scheduler or run locally, depending on the environment variable 'bisect_mode'.
        """
        while self.running:
            if not self.running:
                logger.info("æ¶ˆè´¹è€…çº¿ç¨‹æ”¶åˆ°åœæ­¢ä¿¡å·")
                break
            cycle_start = time.time()
            processed = 0
            try:
                # Fetch bisect tasks from Elasticsearch
                bisect_tasks = self.get_tasks_from_bisect_task()
                if not bisect_tasks:
                    time.sleep(30)
                    continue

                if bisect_tasks:  # If tasks are found
                    # Check the mode of operation from environment variable
                    if os.getenv('bisect_mode') == "submit":
                        # If mode is 'submit', send tasks to the scheduler
                        logger.debug("Submitting bisect tasks to scheduler")
                        self.submit_bisect_tasks(bisect_tasks)
                    else:
                        # If mode is not 'submit', run tasks locally
                        logger.debug("Running bisect tasks locally")
                        # å¤šçº¿ç¨‹åœ¨è¿™é‡Œå¤„ç†? 
                        # ä¸€æ¬¡å¤„ç†ä¸€ä¸ª error_id çš„ç³»åˆ—
                        self.run_bisect_tasks(bisect_tasks)
                processed = len(bisect_tasks)

            except Exception as e:
                # Log any errors that occur during task processing
                logger.error(f"Error in bisect_consumer: {e}")
                # å¼‚å¸¸åä¼‘çœ æ—¶é—´åŠ å€ï¼ˆç®€æ˜“ç†”æ–­æœºåˆ¶ï¼‰
                time.sleep(60)
            finally:
                # è®°å½•å¤„ç†æŒ‡æ ‡
                cycle_time = time.time() - cycle_start
                logger.info(f"Consumer cycle processed {processed} tasks in {cycle_time:.2f}s")

                # åŠ¨æ€ä¼‘çœ æ§åˆ¶ï¼ˆæ— ä»»åŠ¡æ—¶å»¶é•¿ä¼‘çœ ï¼‰
                sleep_time = 30 if processed > 0 else 60
                time.sleep(max(10, sleep_time - cycle_time))  # ä¿è¯æœ€å°é—´éš”
    def run_bisect_tasks(self, bisect_tasks):
        """æ”¹é€ åçš„ä»»åŠ¡æäº¤æ–¹æ³•"""
        if not bisect_tasks:
            return
        futures = []
        for task in bisect_tasks:
            future = self.process_pool.submit(
                self._process_single_task,
                self._config,
                task
            )
            futures.append(future)
            self.task_futures.append(future)

        for future in as_completed(futures, timeout=72000):  # 2å°æ—¶è¶…æ—¶
            try:
                result = future.result()
                if result['status'] == 'success':
                    logger.info(f"ä»»åŠ¡å®Œæˆ: {result['id']}")
                else:
                    logger.error(f"ä»»åŠ¡å¤±è´¥: {result['id']} - {result['error']}")
            except TimeoutError:
                logger.error("ä»»åŠ¡å¤„ç†è¶…æ—¶ï¼Œå¯èƒ½å‘ç”Ÿæ­»é”")
                future.cancel()
            except Exception as e:
                logger.error(f"ç»“æœå¤„ç†å¼‚å¸¸: {str(e)}")

    def update_regression(self, task, result):
        """ä½¿ç”¨ ManticoreClient æ›´æ–°å›å½’æ•°æ®åº“"""
        try:
            # å‚æ•°æ ¡éªŒ
            if not task.get('error_id') or not task.get('bad_job_id'):
                logger.error("Invalid task format for regression update")
                return

            # è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆç§’çº§ï¼‰
            current_time = int(time.time())
            bad_job_id = task['bad_job_id']
            error_id = task['error_id'].replace("'", "''")  # è½¬ä¹‰å•å¼•å·

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æœ‰æ•ˆè®°å½•
            existing = process_client.search(
                table="regression",
                query={
                    "bool": {
                        "must": [
                            {"match": {"record_type": "errid"}},
                            {"match": {"errid": error_id}},
                            {"match": {"valid": "true"}}
                        ]
                    }
                },
                limit=1
            )

            if not existing:
                # æ’å…¥æ–°è®°å½•
                new_id = int(f"{current_time}{randint(1000,9999)}")  # ç”Ÿæˆå”¯ä¸€ID
                category = result.get('category', 'unknown').replace("'", "''")
                related_jobs_json = json.dumps([bad_job_id])  # åˆå§‹åŒ–ä¸ºæ•°ç»„

                new_record = {
                    "id": new_id,
                    "record_type": "errid",
                    "errid": error_id,
                    "category": category,
                    "first_seen": current_time,
                    "last_seen": current_time,
                    "bisect_count": 1,
                    "related_jobs": related_jobs_json,
                    "valid": "true"
                }

                if not process_client.insert("regression", new_id, new_record):
                    logger.error(f"æ’å…¥æ–°è®°å½•å¤±è´¥ | ErrorID: {error_id}")
            else:
                # æ›´æ–°ç°æœ‰è®°å½•
                record = existing[0]
                new_count = record['bisect_count'] + 1
                record_id = record['id']

                update_record = {
                    "bisect_count": new_count,
                    "last_seen": current_time,
                    "related_jobs": json.dumps(record['related_jobs'] + [bad_job_id])
                }

                if not process_client.update("regression", record_id, update_record):
                    logger.error(f"æ›´æ–°è®°å½•å¤±è´¥ | ErrorID: {error_id}")

            logger.info(f"Regression updated | ErrorID: {error_id}")

        except Exception as e:
            logger.error(f"Failed to update regression: {str(e)}")
            logger.error(f"Task: {task} | Result: {result}")

    def submit_bisect_tasks(self, bisect_tasks):
        """
        Submit a list of bisect tasks to the scheduler if they are not already in the database.
        Each task is checked against the database to avoid duplicate submissions.

        :param bisect_tasks: List of bisect tasks to submit.
        """
        # Define the query to check if a bisect task already exists in the database

        # Process each bisect task
        for bisect_task in bisect_tasks:
            task_id = bisect_task["id"]
            try:
                # Check if the task already exists in the database
                result = self.submit_bisect_job(bisect_task["bad_job_id"], bisect_task["error_id"])
                if result:
                    logger.info(f"Submitted bisect task to scheduler: {bisect_task['id']}")
                else:
                    logger.error(f"Submission failed for task {task_id}")
            except KeyError as e:
                # å¤„ç†ä»»åŠ¡æ•°æ®æ ¼å¼é”™è¯¯
                logger.error(f"Invalid task format {task_id}: missing {str(e)}")
            except Exception as e:
                # æ·»åŠ é‡è¯•æœºåˆ¶
                retry_count = 0
                while retry_count < 3:
                    logger.error(f"Submission failed for task {task_id} {retry_count+1} times")
                    try:
                        result = self.submit_bisect_job(bisect_task["bad_job_id"], bisect_task["error_id"])
                        if result:
                           logger.info(f"Submitted bisect task to scheduler: {bisect_task['id']}")
                        break
                    except Exception:
                        retry_count += 1
                        time.sleep(2 ** retry_count)

    def get_tasks_from_bisect_task(self):
        """
        Search for bisect tasks with status 'wait' using Manticore SQL.
        Returns the list of tasks if found, otherwise returns None.

        :return: List of bisect tasks with status 'wait', or None if no tasks are found.
        """
        # Define SQL query
        sql = """
            SELECT * 
            FROM bisect
            WHERE bisect_status = 'wait'
            LIMIT 10
        """

        result = self.bisect_db.execute_query(sql)

        # Return the result if tasks are found, otherwise return None
        if result:
            return result
        else:
            return None

    def submit_bisect_job(self, bad_job_id, error_id):
        """
        Submit a bisect job to the scheduler using the provided bad_job_id and error_id.
        The job is submitted via a shell command, and the job ID is extracted from the response.

        :param bad_job_id: The ID of the bad job to be bisected.
        :param error_id: The error ID associated with the bad job.
        :return: The job ID if submission is successful, otherwise None.
        """

        try:
            submit_command = f"{os.environ['LKP_SRC']}/sbin/submit runtime=36000 bad_job_id={bad_job_id} error_id={error_id} bisect-py.yaml"
            result = subprocess.run(
            submit_command,
            shell=True,
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60)
            match = re.search(r'id=(\S+)', result.stdout)
            if match:
                job_id = match.group(1)
                logger.info(f"Job submitted successfully. Job ID: {job_id}")
                return job_id
            else:
                logger.error(f"Unexpected submit output: {result.stdout}")
                return None
        except subprocess.CalledProcessError as e:
            logger.error(f"Job submission failed with return code {e.returncode}.")
            return None
        except subprocess.TimeoutExpired:
            # å¤„ç†å‘½ä»¤æ‰§è¡Œè¶…æ—¶
            logger.error("Submit command timed out after 30 seconds")
            return None
        except KeyError:
            # å¤„ç†LKP_SRCç¯å¢ƒå˜é‡ç¼ºå¤±
            logger.error("LKP_SRC environment variable not configured")
            return None
        except Exception as e:
            # å…œåº•å¼‚å¸¸å¤„ç†
            logger.error(f"Unexpected error during job submission: {str(e)}")
            return None

    def get_new_bisect_task_from_jobs(self):
        """
        Fetch new bisect tasks using Manticore SQL for both PKGBUILD and SS suites.
        Tasks are filtered based on a white list of error IDs and processed into a standardized format.

        :return: A list of processed tasks that match the white list criteria.
        """
        # Define SQL for PKGBUILD tasks
        # TODO: ä¸åº”è¯¥æ·»åŠ é‡å¤çš„ bad_job_id, é¿å…æ‰¾ä¸åˆ° _url çš„å†…å®¹è¢«æŸ¥æ‰¾
        # å¢åŠ åˆ¤æ–­ AND submit_time > NOW() - INTERVAL 7 DAY
        # Perf monitor
        sql_failure = """
            SELECT id, errid as errid, j.suite as suite, full_text_kv as text
            FROM jobs
            WHERE j.errid IS NOT NULL
            AND (j.program.makepkg._url IS NOT NULL OR j.ss IS NOT NULL)
            AND MATCH('job_health=abort job_stage=finish')
            ORDER BY id DESC
            LIMIT 1000
        """
        # select id, errid, full_text_kv from jobs where match('job_health=abort job_stage=finish') and j.errid is not null and j.program is not null order by id desc limit 1000
        # Define the white list of error IDs
        sql_error_id = """
            SELECT errid
            FROM regression
            WHERE record_type = 'errid'
            AND valid = 'true'
            ORDER BY id DESC
        """
        # TODO: ä¸€ä¸ª bad_job_id åº”è¯¥å’Œç™½åå•åˆ¤æ–­ä¸€æ¬¡
        errid_white_list_raw = self.regression_db.execute_query(sql_error_id)
        errid_white_list = {item['errid'] for item in errid_white_list_raw} if errid_white_list_raw else set()

        # Execute Manticore SQL queries
        result = self.jobs_db.execute_query(sql_failure)
        # Convert the list of tasks into a dictionary with task IDs as keys
        # æ·»åŠ è¯¦ç»†æ—¥å¿—è®°å½•åŸå§‹æ•°æ®æ ¼å¼ 
        # Process the tasks to filter and transform them based on the white list
        errid_tasks = self.process_data(result, errid_white_list)
        # TODO: PERF_TASKS = self.
        # Return the processed tasks
        return errid_tasks

    def process_data(self, input_data, white_list):
        result = []
        for item in input_data:
            try:
                bad_job_id = str(item["id"])
                # ä¿®æ”¹ç‚¹ï¼šç›´æ¥åˆ†å‰²å­—ç¬¦ä¸²ä»£æ›¿JSONè§£æ
                errids = item["errid"].split()  # æŒ‰ç©ºæ ¼åˆ†å‰²å­—ç¬¦ä¸²
                
                # æ ¸å¿ƒé€»è¾‘ï¼šä¼˜å…ˆç™½åå•ï¼Œæ— åŒ¹é…åˆ™å…¨å¤„ç†
                if white_list:  # æ¨¡å¼ä¸€ï¼šå­˜åœ¨ç™½åå•æ—¶
                    candidates = set(errids) & set(white_list)
                    if not candidates:  # ç™½åå•å­˜åœ¨ä½†æ— åŒ¹é…æ—¶å›é€€
                        candidates = errids
                else:  # æ¨¡å¼äºŒï¼šæ— ç™½åå•æ—¶
                    candidates = errids

                # ç”Ÿæˆä»»åŠ¡æ–‡æ¡£
                for errid in candidates:
                    result.append({
                        "bad_job_id": bad_job_id,
                        "error_id": errid,
                        "bisect_status": "wait"
                    })

            except (KeyError, AttributeError) as e:  # ä¿®æ”¹å¼‚å¸¸ç±»å‹
                logger.warning(f"å¤„ç†å¼‚å¸¸æ¡ç›® {item.get('id')}ï¼š{str(e)}")
                continue
        
        logger.info(f"ç”Ÿæˆä»»åŠ¡æ•°ï¼š{len(result)} | ç™½åå•æ¨¡å¼ï¼š{bool(white_list)}")
        return result

    def _start_monitor(self):
        def monitor():
            while True:
                try:
                    logger.info("ğŸ” è¿æ¥æ± ç®€ç•¥çŠ¶æ€:")
                    try:
                        jobs_active = self.jobs_db.pool._cnx_queue.qsize()
                        bisect_active = self.bisect_db.pool._cnx_queue.qsize()
                        bisect_active = self.regression_db.pool._cnx_queue.qsize()
                        logger.info(f"Jobs DB æ´»è·ƒè¿æ¥: {jobs_active}")
                        logger.info(f"Bisect DB æ´»è·ƒè¿æ¥: {bisect_active}")
                        logger.info(f"Regression DB æ´»è·ƒè¿æ¥: {bisect_active}")
                    except AttributeError as e:
                        logger.warning(f"è¿æ¥æ± çŠ¶æ€è·å–å¤±è´¥: {str(e)}")
                    
                    self.jobs_db.check_connection_leaks()
                    self.bisect_db.check_connection_leaks()
                    
                except Exception as e:
                    logger.error(f"ç›‘æ§å¼‚å¸¸: {str(e)}")
                finally:
                    time.sleep(300)
                
        threading.Thread(target=monitor, daemon=True).start()

class BisectAPI(MethodView):
    def __init__(self):
        self.bisect_api = BisectTask()

    def post(self):
        task = request.json
        if not task:
            return jsonify({"error": "No data provided"}), 400
        self.bisect_api.add_bisect_task(task)
        return jsonify({"message": "Task added successfully"}), 200


class ListBisectTasksAPI(MethodView):
    def __init__(self):
        self.bisect_db = BisectDB(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=os.environ.get('MANTICORE_PORT', '9306'),
            database="bisect",
            pool_size=15
        )

    def get(self):
        try:
            # æŸ¥è¯¢æ‰€æœ‰bisectä»»åŠ¡
            tasks = self.bisect_db.execute_query("""
                SELECT id, bad_job_id, error_id, bisect_status 
                FROM bisect 
                ORDER BY id DESC
            """)

            # æ ¼å¼åŒ–è¾“å‡º
            formatted_tasks = []
            for task in tasks:
                formatted_tasks.append({
                    "TASk ID": task['id'],
                    "BAD JOB ID": task['bad_job_id'],
                    "ERROR ID": task['error_id'],
                    "STATUS": {'wait': 'wait', 'processing': 'processing', 'completed': 'finish', 'failed': 'failed'}.get(task['bisect_status'], 'unknown'),
                })

            response_data = {
                "total": len(formatted_tasks),
                "tasks": formatted_tasks
            }
            return json.dumps(response_data, indent=2, ensure_ascii=False), 200, {'Content-Type': 'application/json; charset=utf-8'}

        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            return jsonify({"error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯"}), 500


class ListTasksByStatusAPI(MethodView):
    def __init__(self):
        self.bisect_db = BisectDB(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=os.environ.get('MANTICORE_PORT', '9306'),
            database="bisect",
            pool_size=15
        )

    def get(self):
        try:
            # è·å–æŸ¥è¯¢å‚æ•°ï¼Œé»˜è®¤ä¸º 'completed'
            status = request.args.get('status', 'completed')

            # æŸ¥è¯¢æŒ‡å®šçŠ¶æ€çš„ä»»åŠ¡
            sql = f"""
                SELECT id, bad_job_id, error_id, bisect_status 
                FROM bisect 
                WHERE bisect_status = '{status}'
                ORDER BY id DESC
            """
            tasks = self.bisect_db.execute_query(sql)

            # æ ¼å¼åŒ–è¾“å‡º
            formatted_tasks = []
            for task in tasks:
                formatted_tasks.append({
                    "TASK ID": task['id'],
                    "BAD JOB ID": task['bad_job_id'],
                    "ERROR ID": task['error_id'],
                    "STATUS": {'wait': 'wait', 'processing': 'processing', 'completed': 'finish', 'failed': 'failed'}.get(task['bisect_status'], 'unknown'),
                })

            response_data = {
                "total": len(formatted_tasks),
                "tasks": formatted_tasks
            }
            return json.dumps(response_data, indent=2, ensure_ascii=False), 200, {'Content-Type': 'application/json; charset=utf-8'}

        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")
            return jsonify({"error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯"}), 500


class DeleteFailedTasksAPI(MethodView):
    def __init__(self):
        self.bisect_db = BisectDB(
            host=os.environ.get('MANTICORE_HOST', 'localhost'),
            port=os.environ.get('MANTICORE_PORT', '9306'),
            database="bisect",
            pool_size=15
        )

    def delete(self):
        try:
            # æ‰§è¡Œåˆ é™¤æ“ä½œ
            result = self.bisect_db.execute_delete("""
                DELETE FROM bisect 
                WHERE bisect_status = 'failed'
            """)
            
            logger.info(f"æˆåŠŸåˆ é™¤{result}æ¡å¤±è´¥ä»»åŠ¡")
            return jsonify({
                "status": "success",
                "deleted_count": result
            }), 200

        except Exception as e:
            logger.error(f"åˆ é™¤å¤±è´¥ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            return jsonify({
                "error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
                "details": str(e)
            }), 500

def run_flask():
    """ä½¿ç”¨ç”Ÿäº§çº§ WSGI æœåŠ¡å™¨ï¼Œå¸¦å¼€å‘æœåŠ¡å™¨å›é€€"""
    app.add_url_rule('/new_bisect_task', view_func=BisectAPI.as_view('bisect_api'))
    app.add_url_rule('/list_bisect_tasks', view_func=ListBisectTasksAPI.as_view('list_bisect_tasks'))
    app.add_url_rule('/list_tasks_by_status', view_func=ListTasksByStatusAPI.as_view('list_tasks_by_status'))
    app.add_url_rule('/delete_failed_tasks', view_func=DeleteFailedTasksAPI.as_view('delete_failed_tasks'))
    port = int(os.environ.get('BISECT_API_PORT', 9999))
    
    try:
        from waitress import serve
        serve(app, host='0.0.0.0', port=port, threads=8)
    except ImportError:
        logger.warning("Waitress æœªå®‰è£…ï¼Œä½¿ç”¨å¼€å‘æœåŠ¡å™¨")
        app.run(host='0.0.0.0', port=port)

def main():
    try:
        executor = ThreadPoolExecutor(max_workers=3)
        run = BisectTask()
        executor.submit(run.bisect_producer)
        executor.submit(run_flask)
        executor.submit(run.bisect_consumer)

        # ä¸»çº¿ç¨‹ä¿æŒæ´»è·ƒ
        while True:
            time.sleep(3600)  # é˜²æ­¢ä¸»çº¿ç¨‹é€€å‡º
    except Exception as e:
        logger.error(f"Error when init_bisect_commit: {str(e)}")
        logger.error(traceback.format_exc())  # Add stack trace
        sys.exit(1)


if __name__ == "__main__":
    main()

