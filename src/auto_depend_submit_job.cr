# SPDX-License-Identifier: MulanPSL-2.0+
# Copyright (c) 2020 Huawei Technologies Co., Ltd. All rights reserved.

class Sched

	# for avoiding id duplication
	@@last_jobid = 0_i64

  # API method to handle job submission
  def api_submit_job(job_content : Hash(String, JSON::Any)) : Result
    begin
      # In cluster case, origin_job will be copied to node jobs and dropped,
      # so shall not call on_job_submit() right now.
      origin_job = init_job(job_content)
      checkout_max_run(origin_job)

      origin_job.handle_upload_file_store
      response = origin_job.handle_need_file_store
      if response
        return Result.error(HTTP::Status::BAD_REQUEST, [response].to_json)
      end

      # if has upload_field, return it and notify client resubmit
      fields_need_upload = origin_job.process_user_files_upload
      if fields_need_upload
        return Result.error(HTTP::Status::BAD_REQUEST, [{
          "message" => "#{fields_need_upload}",
          "errcode" => "RETRY_UPLOAD",
        }].to_json)
      end

      # Process the job submission
      jobs = Sched.instance.cluster.handle_job(origin_job)
      response = [] of Hash(String, String)

      jobs.each do |job|
        Sched.instance.pkgbuild.handle_job(job)

        # Now fields changes are done (e.g. wait_on added by pkgbuild),
        # ready for saving to external fs/db
        on_job_submit(job)

        response << {
          "job_id"      => job.id,
          "message"     => "",
          "version"     => Scheduler::VERSION,
          "job_state"   => "submit",
          "result_root" => "#{BASE_DIR}#{job.result_root}",
        }
        @log.info(response.last)
      end

      Result.success(response.to_json)
    rescue e
      @log.warn({
        "message"       => e.inspect_with_backtrace,
        "job_content"   => Sched.public_content(job_content).to_json,
      }) if job_content

      Result.error(HTTP::Status::INTERNAL_SERVER_ERROR, [{
        "job_id"    => "0",
        "job_state" => "submit",
        "message"   => e.inspect_with_backtrace,
      }].to_json)
    end
  end

  # Redact sensitive information from job content
  def self.public_content(job_content : Hash(String, JSON::Any)) : Hash(String, JSON::Any)
    return {} of String => JSON::Any unless job_content

    temp = job_content.clone
    sensitive_fields = [
      "my_email", "my_token", "job_token", "my_ssh_pubkey", "secrets", "pkg_data", "stats"
    ]
    sensitive_fields.each { |field| temp.delete(field) }
    temp
  end

  # Helper method to initialize a job
  def init_job(job_content : Hash(String, JSON::Any)) : Job
    # submit $RESULT_ROOT/job.yaml may carry on these fields generated by
    # previous schedule, so clear these stale data
    stale_fields = [
      "id", "plugins", "errid", "stats",
      "start_time", "end_time", "finish_time",
      "job_health", "job_stage", "job_state"
    ]
    stale_fields.each { |field| job_content.delete(field) }

    # Create and submit the job
    job = Job.new(job_content)
    job.init_submit
    job
  end

  def checkout_max_run(job)
    max_run = job.max_run?
    return unless max_run

    all_params_md5 = job.all_params_md5

    query = {
      "all_params_md5" => "#{all_params_md5}"
    }

    query_result = Sched.instance.es.select("jobs", query, "id")

    total = query_result.size

    msg = "the number of jobs with the same all_params_md5=#{all_params_md5} has reached the limit of max_run=#{max_run}, the total number is #{total}"
    raise msg if total >= max_run.not_nil!.to_i
  end

  # Generates a unique job ID using the current time and the worker ID.
  # The format is: `yyMMddHHmmssSS` (datetime) + `worker_id_padded`.
  # This ensures the ID fits into an Int64 and maintains chronological order.
  #
  # Example:
  #   Time.local.to_s("%y%m%d%H%M%S%3N") + "00" => "25022512311472100"
  #
  # Returns:
  #   A unique job ID as a String.
  def self.get_job_id : String
    time_part = Time.local.to_s("%y%m%d%H%M%S%3N")
    id = "#{time_part}#{@@options.worker_id_padded}"
    id64 = id.to_i64

    # Ensure the generated ID is unique and greater than the last used ID.
    if id64 <= @@last_jobid
      # Increment by cluster_size to avoid conflicts with other workers.
      id64 = @@last_jobid + @@options.cluster_size
      id = id64.to_s
    end

    @@last_jobid = id64
    id
  end

end
