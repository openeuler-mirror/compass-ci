## 部署文档

#### 服务器coordinator部署：

1、安装依赖项：

- 确保服务器上安装了Python和Git
- 使用以下命令安装所需的Python库依赖项

```shell
pip3 install pkg
```

- 编译grpc的proto文件

```shell
python -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. func.proto
```


2、修改配置文件：

- 在coordinator目录下编辑服务器端的配置文件 `config.yaml`，根据实际情况配置其中的参数，例如设置上游Git仓库的信息、服务端IP地址等。

```yaml
coor_ip_addr: 127.0.0.1:5555
upstream_repos_name: upstream-repos-test
upstream_repos_url: https://gitee.com/compass-ci/upstream-repos.git
bitmap_max_num: 100
```

3、运行服务器：

- 在服务器上执行以下命令以启动coordinator，执行路径需在coordinator目录下：

```shell
cd coordinator
python server.py
```

- 服务器将开始监听指定的IP地址和端口号



#### 客户端worker部署：

1、安装依赖项：

- 确保客户端上安装了Python和Git
- 使用以下命令安装所需的Python库依赖项

```shell
pip3 install pkg
```

2、修改配置文件：

- 在worker目录下编辑客户端的配置文件 `config.yaml`，根据实际情况配置其中的参数，确保配置了coordinator的IP地址和端口号，以及worker克隆仓库路径等信息。

```yaml
where_coor_ip_addr: 127.0.0.1:5555
clone_disk_path: /worker/clone/repo/path
```

3、运行worker：

- 在客户端机器上执行以下命令以启动coordinator，执行路径需在worker目录下：

```shell
cd worker
python client.py
```

- worker将连接到coordinator，并开始执行任务。



#### **验证结果**

- 可通过浏览器或HTTP客户端访问coordinator服务器的API接口，只需调用下面的方法即可访问http://localhost:8089/api/status来验证服务器是否正常运行，以及查看每个worker管理的仓库：

```python
app.run(host='0.0.0.0', port=8089) # 可自行修改IP和端口
```

- 在worker端终端上，能够看到与coordinator的连接和任务执行的相关输出。

- 启动coordinator，可以看到一系列的前置操作输出日志，准备结束后将开始启动grpc服务，开始监听对应的IP端口，并会定期git pull上游仓库（即配置文件中指定的上游仓库）：

```
start read config file...
upsteam仓库不存在!
upstream仓库克隆成功! 
no cache!
start rpc...
git_tree build ok!
distribute repo to worker is ok!
result.stdout:  已经是最新的。

result.stdout:  已经是最新的。

result.stdout:  已经是最新的。

result.stdout:  已经是最新的。

result.stdout:  已经是最新的。

result.stdout:  已经是最新的。
```

- 当有worker成功连接时，coordinator将会响应，返回对应的worker唯一ID以及uuid等信息，并且将worker负责的url发送给worker，worker收到grpc的respone后开始检查本地指定克隆路径下是否有此仓库，如果有则开始根据优先级加入到任务队列中开始定期fetch，如果没有则执行克隆操作，worker端打印日志如下：

```
连接coordinator成功! workerID: 0 uuid: 0e6e54cc-55cc-11ee-a4f1-31326e2fd21f
开始尝试clone...
开始尝试clone...
开始尝试clone...
开始尝试clone...
开始尝试clone...
开始尝试clone...
repo克隆成功! 
start fetch  https://github.com/yanyanran/upstream-repos-test.git
repo克隆成功! 
start fetch  https://github.com/gueFDF/Go.git
repo克隆成功! 
start fetch  https://github.com/yanyanran/YBlog.git
repo克隆成功! 
start fetch  https://github.com/yanyanran/GitMirror.git
repo克隆成功! 
start fetch  https://github.com/gueFDF/MIT_6.824.git
仓库fetch成功!
start fetch  https://github.com/gueFDF/Go.git
仓库fetch成功!
start fetch  https://github.com/yanyanran/upstream-repos-test.git
repo克隆成功! 
start fetch  https://github.com/yanyanran/pictures.git
仓库fetch成功!
start fetch  https://github.com/yanyanran/YBlog.git
仓库fetch成功!
start fetch  https://github.com/yanyanran/GitMirror.git
仓库fetch成功!
start fetch  https://github.com/gueFDF/MIT_6.824.git
仓库fetch成功!
```

coordinator服务端打印日志如下：

```
worker[0]已连接!
收到 worker:  0 的心跳
result.stdout:  已经是最新的。

收到 worker:  0 的心跳
收到 worker:  0 的心跳
result.stdout:  已经是最新的。

收到 worker:  0 的心跳
收到 worker:  0 的心跳
result.stdout:  已经是最新的。
```

- worker连接后会定期向coordinator端发送心跳包，当worker断连后coordinator端将会感应到，worker连接超时到判定worker挂机有一段时间，在这个时间区间内如果worker重新恢复连接，将照旧运行；超时则判为worker挂机，将会删除在coordinator端对worker的缓存，并将分配给该worker的仓库通过一致性哈希算法较为均匀地分配给其他worker。coordinator打印日志如下：

```
【Worker Timeout】worker 0 连接超时!
【Worker Dieout】worker 0 挂了!拜拜！
```

- 倘若coordinator挂机，worker将会通过定期发送的心跳包感应到coordinator挂机，worker端打印日志并退出进程：

```
检测到coordinator挂机!
仓库fetch成功!
Exception in thread Thread-1 (process_tasks):
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/yanran/github/ospp-GitMirror/worker/client.py", line 190, in process_tasks
    thread_pool.submit(task.fetch_repo,self.task_queue)  
  File "/usr/lib/python3.10/concurrent/futures/thread.py", line 167, in submit
    raise RuntimeError('cannot schedule new futures after shutdown')
RuntimeError: cannot schedule new futures after shutdown
仓库fetch成功!
仓库fetch成功!
仓库fetch成功!
仓库fetch成功!
仓库fetch成功!
```

- 关于数据的持久化，体现在coordinator/worker.db和worker/self.db。其中worker.db中存储连接到coordinator上worker的各项信息，而self.db则是每个worker自己的元数据以及管理的仓库url。