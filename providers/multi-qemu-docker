#!/usr/bin/env ruby

require 'optparse'
require 'json'
require 'fileutils'
require 'yaml'
require 'faye/websocket'
require 'eventmachine'

# Load common libraries
require_relative 'lib/common'
require_relative 'lib/jwt'
require_relative 'lib/job_tracker'
require_relative 'docker/docker'
require_relative 'qemu'
require_relative '../../container/defconfig'

names = Set.new %w[
  SCHED_HOST
  SCHED_PORT
  DOMAIN_NAME
]

defaults = relevant_defaults(names)
SCHED_HOST = ENV['SCHED_HOST'] || defaults['SCHED_HOST'] || '172.17.0.1'
SCHED_PORT = ENV['SCHED_HOST'] || defaults['SCHED_PORT'] || 3000

DOMAIN_NAME = defaults['DOMAIN_NAME']
ARCH = get_arch

class MultiQemuDocker
  DEFAULT_OPTIONS = {
    hostname: ENV['HOSTNAME'] || 'default-host',
    tbox_type: 'qemu,container',
    max_qemu: 0,
    max_container: 0,
    is_remote: false
  }.freeze

  MAX_QEMU_PER_CPU = 4
  MAX_CONTAINER_PER_CPU = 2
  MIN_QEMU_MEMORY = 4       # GB
  MIN_CONTAINER_MEMORY = 8  # GB

  HEARTBEAT_INTERVAL = 10   # seconds
  MEM_CHECK_INTERVAL = 1    # second
  MEM_DELTA_THRESHOLD = 100 # 100MB

  attr_reader :options, :scheduler_url, :scheduler_ws_url
  attr_accessor :last_free_mem, :last_status_time

  def initialize(argv)
    @options = DEFAULT_OPTIONS.merge(parse_cli_options(argv))
    @scheduler_url = build_scheduler_url
    @scheduler_ws_url = build_scheduler_ws_url
    @last_meminfo = parse_meminfo
    @last_free_mem = free_memory_mb
    @last_status_time = Time.now
    setup_directories
    @jobs = JobTracker.new
  end

  def setup_directories
    File.umask(0000) # Ensure directories are created with proper permissions
    FileUtils.mkdir_p(ENV["HOSTS_DIR"] = "/srv/cci/hosts")
    FileUtils.mkdir_p(ENV["JOBS_DIR"] = "/srv/cci/jobs")
    FileUtils.mkdir_p(ENV["PIDS_DIR"] = "/srv/cci/pids")
    FileUtils.mkdir_p(ENV["LOGS_DIR"] = "/srv/cci/logs")
  end

  def open_websocket(url)
    if is_remote.to_s == 'true'
      jwt = load_jwt?
      ws = Faye::WebSocket::Client.new(url, [], :headers => { 'Authorization' => jwt })
    else
      ws = Faye::WebSocket::Client.new(url)
    end
    ws
  end

  def start_event_machine
    EM.run do
      @ws = open_websocket(@scheduler_ws_url)

      @ws.on(:open) do
        puts "WebSocket connection opened"
        send_status
        start_heartbeat
        start_mem_monitoring
        start_job_monitoring
      end

      @ws.on(:message) do |event|
        puts "Received: #{event.data}"
        handle_websocket_message(event.data)
      end

      @ws.on(:close) do |event|
        puts "WebSocket closed with code #{event.code}"
        safe_stop
        EM.stop
      end
    end
  rescue => e
    puts "WebSocket error: #{e.message}"
    retry
  end


  private

  def parse_cli_options(argv)
    options = {}

    OptionParser.new do |opts|
      opts.banner = 'Usage: multi-qemu-docker [options]'

      opts.on('-n HOSTNAME', '--name HOSTNAME', 'Hostname for reporting') { |v| options[:hostname] = v }
      opts.on('-t TYPE', '--tbox-type TYPE', 'Testbox type (qemu, container, or both by default)') { |v| options[:tbox_type] = v }
      opts.on('--max-qemu COUNT', 'Number of QEMU instances (0 for auto-computing)') { |v| options[:max_qemu] = v }
      opts.on('--max-container COUNT', 'Number of container instances (0 for auto-computing)') { |v| options[:max_container] = v }
      opts.on('-t tags', '--tags TAGS', 'separated by ","') { |v| opt['tags'] = v }
      opts.on('-r', '--remote', 'Testbox is remote') { options[:is_remote] = true }
      opts.on('-h', '--help', 'Show this message') { puts opts; exit }
    end.parse!(argv)

    options
  end

  def build_scheduler_url
    if @options[:is_remote]
      "https://#{DOMAIN_NAME}/"
    else
      "http://#{SCHED_HOST}:#{SCHED_PORT}/"
    end
  end

  def build_scheduler_ws_url
    if @options[:is_remote]
      "wss://#{DOMAIN_NAME}/ws/vm-container-provider"
    else
      "ws://#{SCHED_HOST}:#{SCHED_PORT}/ws/vm-container-provider"
    end
  end

  def send_status
    status = {
      type: 'host-job-request',
      host_machine: @options[:hostname],
      freemem: free_memory_mb,
      tbox_type: @options[:tbox_type],
      is_remote: @options[:is_remote],
      arch: ARCH
    }
    @ws.send(status.to_json)
  end

  def total_memory_mb
    @last_meminfo["MemTotal"]
  end

  def free_memory_mb
    @last_meminfo["MemFree"]
  end

  def parse_meminfo
    meminfo_hash = {}
    File.open('/proc/meminfo', 'r') do |file|
      file.each_line do |line|
        key, value = line.split(':')
        meminfo_hash[key.strip] = value.strip.to_i / 1024 # Convert bytes to MiB
      end
    end
    meminfo_hash
  end

  def start_heartbeat
    EM.add_periodic_timer(HEARTBEAT_INTERVAL) { send_status }
  end

  def start_mem_monitoring
    EM.add_periodic_timer(MEM_CHECK_INTERVAL) do
      @last_meminfo = parse_meminfo
      current_mem = free_memory_mb
      if (current_mem - @last_free_mem).abs > MEM_DELTA_THRESHOLD || Time.now - @last_status_time > HEARTBEAT_INTERVAL
        @last_free_mem = current_mem
        send_status
        @last_status_time = Time.now
      end
    end
  end

  def start_job_monitoring
    # Placeholder for job monitoring implementation
    # Implement logic to detect job finish events and trigger status update
  end

  def handle_websocket_message(data)
    message = JSON.parse(data)
    case message['type']
    when 'boot-job'
      boot_job(message)
    when 'cancel-job'
      cancel_job(message)
    when 'watch-job-log'
      watch_log(message)
    when 'unwatch-job-log'
      unwatch_log(message)
    else
      puts "Unknown message type: #{message['type']}"
    end
  end

  def boot_job(message)
    job_id = message['job_id']
    puts "Dispatching job: #{message}"

    hostname = @jobs.find_hostname(message['tbox_group'])
    message['hostname'] = hostname
    fork_pid = Process.fork
    if fork_pid == nil
      ENV["hostname"] = hostname
      ENV["host_dir"] = "#{ENV["HOSTS_DIR"]}/#{hostname}"
      ENV["log_file"] = "#{ENV["LOGS_DIR"]}/#{hostname}"
      ENV["is_remote"] = @options[:is_remote].to_s
      case message['tbox_type']
      when 'qemu'
        fork_pid = start_qemu_instance(message)
      when 'container'
        fork_pid = start_container_instance(message)
      end
    else
      Process.detach(fork_pid)
      job = {
        id: job_id
        tbox_type: message['tbox_type']
        hostname: hostname
        fork_pid: fork_pid
      }
      @jobs.add_job(job)
    end
  end

  def cancel_job(message)
    job_id = message['job_id']
    puts "Canceling job: #{job_id}"
    @jobs.stop_job(job_id)
  end

  def watch_log(message)
    job_id = message['job_id']
    job = @jobs[job_id]
    log_file = "#{ENV["LOGS_DIR"]}/#{job[:hostname]}.log"

    # Create a pipe to capture the output of the tail process
    reader, writer = IO.pipe

    # Start the tail process using spawn
    tail_pid = spawn("tail --pid #{job[:fork_pid]} -F #{log_file}", out: writer)
    # Process.detach(tail_pid) # avoid zombie processes

    # Store the tail process PID and pipe reader
    @jobs[job_id][:tail_pid] = tail_pid
    @jobs[job_id][:tail_reader] = reader

    # Read from the pipe in a separate thread
    Thread.new do
      begin
        while line = reader.gets
          # Send log output to WebSocket
          @ws.send({ type: 'log', job_id: job_id, data: line }.to_json)
        end
      rescue IOError => e
        puts "Error reading from tail process for job #{job_id}: #{e.message}"
      ensure
        reader.close
        writer.close
        Process.wait(tail_pid) # avoid zombie processes
      end
    end
  end

  def unwatch_log(message)
    job_id = message['job_id']
    job = @jobs[job_id]

    if job && job[:tail_pid]
      # Terminate the tail process
      Process.kill("TERM", job[:tail_pid])

      # Close the pipe
      if job[:tail_reader]
        job[:tail_reader].close
        job.delete(:tail_reader)
      end

      # Clean up the stored PID
      job.delete(:tail_pid)
      puts "Stopped log watching for job #{job_id}"
    else
      puts "No log watching process found for job #{job_id}"
    end
  end

  def tail_log(job_id)
    # Log streaming logic using WebSocket
    system("tail -f /srv/cci/serial/logs/#{job_id}.log")
  end

  def safe_stop
    # Graceful shutdown logic
    EventMachine.stop
    system("systemctl stop #{ENV['suite']}.service")
  end
end

MultiQemuDocker.new(ARGV).start_event_machine if __FILE__ == $PROGRAM_NAME

